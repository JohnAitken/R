# Print the resulting data frame
print(df)
# List all files with a ".png" extension in the working directory
png_files <- list.files(pattern = "\\.png$")
# Check if there are any files to delete HAVE TO FIX THis
if (length(png_files) > 0) {
# Remove all files with a ".png" extension
file.remove(png_files)
cat("Deleted", length(png_files), "PNG files.\n")
} else {
cat("No PNG files found in the working directory.\n")
}
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
pdf_file <- "10088075_10055_202324.pdf"
text <- ocr(pdf_file, engine = eng)
# Split the text by newline characters
text_lines1 <- strsplit(text, "\n")[[2]]
text_lines2 <- strsplit(text, "\n")[[3]]
text_lines3 <- strsplit(text, "\n")[[4]]
text_lines4 <- strsplit(text, "\n")[[5]]
# Create a data frame with the text as columns
df <- data.frame(text_lines, stringsAsFactors = FALSE)
# Print the resulting data frame
print(df)
# List all files with a ".png" extension in the working directory
png_files <- list.files(pattern = "\\.png$")
# Check if there are any files to delete HAVE TO FIX THis
if (length(png_files) > 0) {
# Remove all files with a ".png" extension
file.remove(png_files)
cat("Deleted", length(png_files), "PNG files.\n")
} else {
cat("No PNG files found in the working directory.\n")
}
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
# Specify the PDF file
pdf_file <- "10088075_10055_202324.pdf"
# Perform OCR to get the concatenated text for all pages
text <- ocr(pdf_file, engine = eng)
# Define the number of pages
num_pages <- 4  # Update with the actual number of pages
# Initialize a list to store text for each page
all_text <- list()
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
text_lines <- strsplit(text, "\n")[[page_num]]
# Assign to a dynamically created variable
assign(paste0("text_lines", page_num - 1), text_lines)
# Store in the list
all_text[[page_num - 1]] <- text_lines
}
# Combine the results into a single data frame
df <- data.frame(all_text, stringsAsFactors = FALSE)
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
# Specify the PDF file
pdf_file <- "10088075_10055_202324.pdf"
# Perform OCR to get the concatenated text for all pages
text <- ocr(pdf_file, engine = eng)
# Define the number of pages
num_pages <- 4  # Update with the actual number of pages
# Initialize a list to store results
all_results <- list()
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
text_lines <- strsplit(text, "\n")[[page_num]]
# Store in the list along with page number
all_results <- c(all_results, list(data.frame(text_lines = text_lines, page = page_num - 1)))
}
# Combine the results into a single data frame
df <- do.call(rbind, all_results)
# Print the resulting data frame
print(df)
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
# Specify the PDF file
pdf_file <- "10088075_10055_202324.pdf"
# Perform OCR to get the concatenated text for all pages
text <- ocr(pdf_file, engine = eng)
# Define the number of pages
num_pages <- 4  # Update with the actual number of pages
# Initialize a list to store results
all_results <- list()
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
text_lines <- strsplit(text, "\n")[[page_num]]
# Create a data frame with text_lines, page, and index columns
result_df <- data.frame(
text_lines = text_lines,
page = page_num - 1,
index = seq_along(text_lines)
)
# Store in the list
all_results <- c(all_results, list(result_df))
}
# Combine the results into a single data frame
df <- do.call(rbind, all_results)
# Print the resulting data frame
print(df)
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
# Specify the PDF file
pdf_file <- "10088075_10055_202324.pdf"
# Perform OCR to get the concatenated text for all pages
text <- ocr(pdf_file, engine = eng)
# Define the number of pages
num_pages <- 4  # Update with the actual number of pages
# Initialize a list to store results
all_results <- list()
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
text_lines <- strsplit(text, "\n")[[page_num]]
# Create a data frame with index, page, and text_lines columns
result_df <- data.frame(
index = seq_along(text_lines),
page = page_num - 1,
text_lines = text_lines
)
# Store in the list
all_results <- c(all_results, list(result_df))
}
# Combine the results into a single data frame
df <- do.call(rbind, all_results)
# Print the resulting data frame
print(df)
# VERSION 3
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
# Specify the PDF file
pdf_file <- "10088075_10055_202324.pdf"
# Perform OCR to get the concatenated text for all pages
text <- ocr(pdf_file, engine = eng)
# Define the number of pages
num_pages <- 4  # Update with the actual number of pages
# Initialize a list to store results
all_results <- list()
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
text_lines <- strsplit(text, "\n")[[page_num]]
# Create a data frame with index, page, text_lines, and pdf_file columns
result_df <- data.frame(
index = seq_along(text_lines),
page = page_num - 1,
text_lines = text_lines,
pdf_file = pdf_file
)
# Store in the list
all_results <- c(all_results, list(result_df))
}
# Combine the results into a single data frame
df <- do.call(rbind, all_results)
# Print the resulting data frame
print(df)
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
# Specify the PDF file
pdf_file <- "10088075_10055_202324.pdf"
# Perform OCR to get the concatenated text for all pages
text <- ocr(pdf_file, engine = eng)
# Define the number of pages
num_pages <- 4  # Update with the actual number of pages
# Initialize a list to store results
all_results <- list()
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
text_lines <- strsplit(text, "\n")[[page_num]]
# Create a data frame with index, page, text_lines, and pdf_file columns
result_df <- data.frame(
index = seq_along(text_lines),
page = page_num - 1,
text_lines = text_lines,
pdf_file = pdf_file
)
# Store in the list
all_results <- c(all_results, list(result_df))
}
# Combine the results into a single data frame
df <- do.call(rbind, all_results)
# Print the resulting data frame
print(df)
# Delete the PNGs in folder
png_files <- list.files(pattern = "\\.png$")
# Check if there are any files to delete
if (length(png_files) > 0) {
# Remove all files with a ".png" extension
file.remove(png_files)
cat("Deleted", length(png_files), "PNG files.\n")
} else {
cat("No PNG files found in the working directory.\n")
}
# Record the start time
start_time <- Sys.time()
# Your existing code here
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
# Specify the PDF file
pdf_file <- "10088075_10055_202324.pdf"
# Perform OCR to get the concatenated text for all pages
text <- ocr(pdf_file, engine = eng)
# Define the number of pages
num_pages <- 4  # Update with the actual number of pages
# Initialize a list to store results
all_results <- list()
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
text_lines <- strsplit(text, "\n")[[page_num]]
# Create a data frame with index, page, text_lines, and pdf_file columns
result_df <- data.frame(
index = seq_along(text_lines),
page = page_num - 1,
text_lines = text_lines,
pdf_file = pdf_file
)
# Store in the list
all_results <- c(all_results, list(result_df))
}
# Combine the results into a single data frame
df <- do.call(rbind, all_results)
# Print the resulting data frame
print(df)
# Delete the PNGs in folder
png_files <- list.files(pattern = "\\.png$")
# Check if there are any files to delete
if (length(png_files) > 0) {
# Remove all files with a ".png" extension
file.remove(png_files)
cat("Deleted", length(png_files), "PNG files.\n")
} else {
cat("No PNG files found in the working directory.\n")
# Record the end time
end_time <- Sys.time()
# Calculate the elapsed time
elapsed_time <- end_time - start_time
# Print the elapsed time
cat("Elapsed time:", format(elapsed_time, units = "secs"), "\n")
}
# Record the start time
start_time <- Sys.time()
# Your existing code here
library(tesseract)
library(tidyverse)
# Set the working directory
setwd("C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev")
# Initialize tesseract engine for English
eng <- tesseract("eng")
# Specify the PDF file
pdf_file <- "10088075_10055_202324.pdf"
# Perform OCR to get the concatenated text for all pages
text <- ocr(pdf_file, engine = eng)
# Define the number of pages
num_pages <- 4  # Update with the actual number of pages
# Initialize a list to store results
all_results <- list()
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
text_lines <- strsplit(text, "\n")[[page_num]]
# Create a data frame with index, page, text_lines, and pdf_file columns
result_df <- data.frame(
index = seq_along(text_lines),
page = page_num - 1,
text_lines = text_lines,
pdf_file = pdf_file
)
# Store in the list
all_results <- c(all_results, list(result_df))
}
# Combine the results into a single data frame
df <- do.call(rbind, all_results)
# Print the resulting data frame
print(df)
# Delete the PNGs in folder
png_files <- list.files(pattern = "\\.png$")
# Check if there are any files to delete
if (length(png_files) > 0) {
# Remove all files with a ".png" extension
file.remove(png_files)
cat("Deleted", length(png_files), "PNG files.\n")
} else {
cat("No PNG files found in the working directory.\n")
}
# Record the end time
end_time <- Sys.time()
# Calculate the elapsed time
elapsed_time <- end_time - start_time
# Print the elapsed time
cat("Elapsed time:", format(elapsed_time, units = "secs"), "\n")
View(df)
lintr:::addin_lint()
lintr:::addin_lint()
styler:::style_active_file()
install.packages('addinslist')
addinslist:::addinslistAddin()
styler:::style_active_file()
styler:::style_selection()
ayu_light_owl <- "https://raw.githubusercontent.com/js-oh/ayu-light-owl/master/ayu-light-owl.rstheme"
rstudioapi::addTheme(ayu_light_owl, apply = TRUE)
# ATTEMPT 5
start_time <- Sys.time()
library(tesseract)
library(tidyverse)
# Set your working directory to the folder containing PDF files
pdf_folder <- "C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev"
setwd(pdf_folder)
# Tesseract read
eng <- tesseract("eng")
# Get a list of all PDF files in the folder
pdf_files <- list.files(pattern = "\\.pdf$", full.names = TRUE)
# Initialize a list to store results
all_results <- list()
# Loop through each PDF file
for (pdf_file in pdf_files) {
cat("Processing file:", pdf_file, "\n")
# Perform OCR on the PDF file
text <- ocr(pdf_file, engine = eng)
# Determine the number of pages in the PDF
num_pages <- length(strsplit(text, "\n")[[1]])
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
if (length(text) >= page_num) {
text_lines <- strsplit(text, "\n")[[page_num]]
if (length(text_lines) > 0) {
# Create a data frame with index, page, text_lines, and pdf_file columns
result_df <- data.frame(
pdf_file = pdf_file,
page = page_num - 1,
text_lines = text_lines
)
all_results <- c(all_results, list(result_df))
}
}
}
}
# Combine the results into a single data frame
df <- dplyr::bind_rows(all_results)
# Delete any PNGs in folder left over from the OCR
png_files <- list.files(pattern = "\\.png$")
if (length(png_files) > 0) {
# Remove all files with a ".png" extension
file.remove(png_files)
cat("Deleted", length(png_files), "PNG files.\n")
} else {
cat("No PNG files found in the working directory.\n")
}
# Print the elapsed time to process
end_time <- Sys.time()
elapsed_time <- end_time - start_time
cat("Elapsed time:", format(elapsed_time, units = "secs"), "\n")
str(df)
str(df)
library(tidyverse)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
View(dfx)
str(dfx)
str(df)
str(df)
# ATTEMPT 5
start_time <- Sys.time()
library(tesseract)
library(tidyverse)
# Set your working directory to the folder containing PDF files
pdf_folder <- "C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev"
setwd(pdf_folder)
# Tesseract read
eng <- tesseract("eng")
# Get a list of all PDF files in the folder
pdf_files <- list.files(pattern = "\\.pdf$", full.names = TRUE)
# Initialize a list to store results
all_results <- list()
# Loop through each PDF file
for (pdf_file in pdf_files) {
cat("Processing file:", pdf_file, "\n")
# Perform OCR on the PDF file
text <- ocr(pdf_file, engine = eng)
# Determine the number of pages in the PDF
num_pages <- length(strsplit(text, "\n")[[1]])
# Loop through pages 2 to num_pages+1
for (page_num in 2:(num_pages + 1)) {
if (length(text) >= page_num) {
text_lines <- strsplit(text, "\n")[[page_num]]
if (length(text_lines) > 0) {
# Create a data frame with index, page, text_lines, and pdf_file columns
result_df <- data.frame(
pdf_file = pdf_file,
page = page_num - 1,
text_lines = text_lines
)
all_results <- c(all_results, list(result_df))
}
}
}
}
# Combine the results into a single data frame
df <- dplyr::bind_rows(all_results)
# Delete any PNGs in folder left over from the OCR
png_files <- list.files(pattern = "\\.png$")
if (length(png_files) > 0) {
# Remove all files with a ".png" extension
file.remove(png_files)
cat("Deleted", length(png_files), "PNG files.\n")
} else {
cat("No PNG files found in the working directory.\n")
}
# Print the elapsed time to process
end_time <- Sys.time()
elapsed_time <- end_time - start_time
cat("Elapsed time:", format(elapsed_time, units = "secs"), "\n")
str(df)
str(df)
pdf_folder <- "C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev"
setwd(pdf_folder
pdf_folder <- "C:/Users/JA/Documents/Git_Repositories/R/pdfScrapeDev"
setwd(pdf_folder)
str(df)
library(tidyverse)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
library(tidyverse)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
glimpse(df)
library(tidyverse)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
glimpse(dfx)
library(tidyverse)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
glimpse(dfx)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
glimpse(dfx)
str(dfx)
library(tidyverse)
dfz <- filter(dfx, cell_type == FALSE)
dfz <- filter(dfx, remove_tag == FALSE)
dfz <- filter(dfx, remove_tag == FALSE)
str(dfx)
dfz <- filter(dfx, remove_tag = FALSE)
str(dfx)
dfx %>% filter(remove_tag == TRUE )
str(dfx)
dfx %>% filter(remove_tag == TRUE )
dfx %>% filter(remove_tag == "TRUE" )
dfx %>% filter(remove_tag == "TRUE")
st(dfx)
str(dfx)
dfx %>% filter(remove_tag == "TRUE") %>% str()
df_filtered <- dfx %>% filter(remove_tag == "TRUE") %>% str()
as.dataframe(df_filtered) <- dfx %>% filter(remove_tag == "TRUE") %>% str()
data.frame(df_filtered) <- dfx %>% filter(remove_tag == "TRUE") %>% str()
dfs <- dfx %>% filter(remove_tag == "TRUE") %>% str()
library(tidyverse)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
glimpse(dfx)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
glimpse(dfx)
str(dfx)
dfs <- dfx %>% filter(remove_tag == "TRUE") %>% str()
library(tidyverse)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
glimpse(dfx)
str(dfx)
dfx <- dfx %>% filter(remove_tag == "TRUE") %>% str()
df_f <- dfx %>%
filter(remove_tag == "TRUE")
df_f <- filter(dfx, remove_tag == "TRUE")
library(tidyverse)
setwd("~/Git_Repositories/R/pdfScrapeDev")
dfx <- read.csv("raw_extract.csv")
glimpse(dfx)
df_f <- filter(dfx, remove_tag == "TRUE")
nrow(dfx)
df_f <- filter(dfx, remove_tag == "TRUE")
nrow(df_f)
